{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af586064",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from random import randint\n",
    "from time import sleep\n",
    "from IPython.display import clear_output\n",
    "from math import ceil,floor\n",
    "from IPython.display import display\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "class PongAgent:\n",
    "    \n",
    "    def __init__(self, game, policy=None, discount_factor = 0.1, learning_rate = 0.1, ratio_explotacion = 0.9):\n",
    "\n",
    "        # Creamos la tabla de politicas\n",
    "        if policy is not None:\n",
    "            self._q_table = policy\n",
    "        else:\n",
    "            position = list(game.positions_space.shape)\n",
    "            position.append(len(game.action_space))\n",
    "            self._q_table = np.zeros(position)\n",
    "        \n",
    "        self.discount_factor = discount_factor\n",
    "        self.learning_rate = learning_rate\n",
    "        self.ratio_explotacion = ratio_explotacion\n",
    "\n",
    "    def get_next_step(self, state, game):\n",
    "        \n",
    "        # Damos un paso aleatorio...\n",
    "        next_step = np.random.choice(list(game.action_space))\n",
    "        \n",
    "        # o tomaremos el mejor paso...\n",
    "        if np.random.uniform() <= self.ratio_explotacion:\n",
    "            # tomar el maximo\n",
    "            idx_action = np.random.choice(np.flatnonzero(\n",
    "                    self._q_table[state[0],state[1],state[2]] == self._q_table[state[0],state[1],state[2]].max()\n",
    "                ))\n",
    "            next_step = list(game.action_space)[idx_action]\n",
    "\n",
    "        return next_step\n",
    "\n",
    "    # actualizamos las politicas con las recompensas obtenidas\n",
    "    def update(self, game, old_state, action_taken, reward_action_taken, new_state, reached_end):\n",
    "        idx_action_taken =list(game.action_space).index(action_taken)\n",
    "\n",
    "        actual_q_value_options = self._q_table[old_state[0], old_state[1], old_state[2]]\n",
    "        actual_q_value = actual_q_value_options[idx_action_taken]\n",
    "\n",
    "        future_q_value_options = self._q_table[new_state[0], new_state[1], new_state[2]]\n",
    "        future_max_q_value = reward_action_taken  +  self.discount_factor*future_q_value_options.max()\n",
    "        if reached_end:\n",
    "            future_max_q_value = reward_action_taken #maximum reward\n",
    "\n",
    "        self._q_table[old_state[0], old_state[1], old_state[2], idx_action_taken] = actual_q_value + \\\n",
    "                                              self.learning_rate*(future_max_q_value -actual_q_value)\n",
    "    \n",
    "    def print_policy(self):\n",
    "        for row in np.round(self._q_table,1):\n",
    "            for column in row:\n",
    "                print('[', end='')\n",
    "                for value in column:\n",
    "                    print(str(value).zfill(5), end=' ')\n",
    "                print('] ', end='')\n",
    "            print('')\n",
    "            \n",
    "    def get_policy(self):\n",
    "        return self._q_table\n",
    "\n",
    "\n",
    "\n",
    "class PongEnvironment:\n",
    "    \n",
    "    def __init__(self, max_life=3, height_px = 40, width_px = 50, movimiento_px = 3):\n",
    "        \n",
    "        self.action_space = ['Arriba','Abajo']\n",
    "        \n",
    "        self._step_penalization = 0\n",
    "        \n",
    "        self.state = [0,0,0]\n",
    "        \n",
    "        self.total_reward = 0\n",
    "        \n",
    "        self.dx = movimiento_px\n",
    "        self.dy = movimiento_px\n",
    "        \n",
    "        filas = ceil(height_px/movimiento_px)\n",
    "        columnas = ceil(width_px/movimiento_px)\n",
    "        \n",
    "        self.positions_space = np.array([[[0 for z in range(columnas)] \n",
    "                                                  for y in range(filas)] \n",
    "                                                     for x in range(filas)])\n",
    "\n",
    "        self.lives = max_life\n",
    "        self.max_life=max_life\n",
    "        \n",
    "        self.x = randint(int(width_px/2), width_px) \n",
    "        self.y = randint(0, height_px-10)\n",
    "        \n",
    "        self.player_alto = int(height_px/4)\n",
    "\n",
    "        self.player1 = self.player_alto  # posic. inicial del player\n",
    "        \n",
    "        self.score = 0\n",
    "        \n",
    "        self.width_px = width_px\n",
    "        self.height_px = height_px\n",
    "        self.radio = 2.5\n",
    "\n",
    "    def reset(self):\n",
    "        self.total_reward = 0\n",
    "        self.state = [0,0,0]\n",
    "        self.lives = self.max_life\n",
    "        self.score = 0\n",
    "        self.x = randint(int(self.width_px/2), self.width_px) \n",
    "        self.y = randint(0, self.height_px-10)\n",
    "        return self.state\n",
    "\n",
    "    def step(self, action, animate=False):\n",
    "        self._apply_action(action, animate)\n",
    "        done = self.lives <=0 # final\n",
    "        reward = self.score\n",
    "        reward += self._step_penalization\n",
    "        self.total_reward += reward\n",
    "        return self.state, reward , done\n",
    "\n",
    "    def _apply_action(self, action, animate=False):\n",
    "        \n",
    "        if action == \"Arriba\":\n",
    "            self.player1 += abs(self.dy)\n",
    "        elif action == \"Abajo\":\n",
    "            self.player1 -= abs(self.dy)\n",
    "            \n",
    "        self.avanza_player()\n",
    "\n",
    "        self.avanza_frame()\n",
    "\n",
    "        if animate:\n",
    "            clear_output(wait=True);\n",
    "            fig = self.dibujar_frame()\n",
    "            plt.show()\n",
    "\n",
    "        self.state = (floor(self.player1/abs(self.dy))-2, floor(self.y/abs(self.dy))-2, floor(self.x/abs(self.dx))-2)\n",
    "    \n",
    "    def detectaColision(self, ball_y, player_y):\n",
    "        if (player_y+self.player_alto >= (ball_y-self.radio)) and (player_y <= (ball_y+self.radio)):\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "    \n",
    "    def avanza_player(self):\n",
    "        if self.player1 + self.player_alto >= self.height_px:\n",
    "            self.player1 = self.height_px - self.player_alto\n",
    "        elif self.player1 <= -abs(self.dy):\n",
    "            self.player1 = -abs(self.dy)\n",
    "\n",
    "    def avanza_frame(self):\n",
    "        self.x += self.dx\n",
    "        self.y += self.dy\n",
    "        if self.x <= 3 or self.x > self.width_px:\n",
    "            self.dx = -self.dx\n",
    "            if self.x <= 3:\n",
    "                ret = self.detectaColision(self.y, self.player1)\n",
    "\n",
    "                if ret:\n",
    "                    self.score = 10\n",
    "                else:\n",
    "                    self.score = -10\n",
    "                    self.lives -= 1\n",
    "                    if self.lives>0:\n",
    "                        self.x = randint(int(self.width_px/2), self.width_px)\n",
    "                        self.y = randint(0, self.height_px-10)\n",
    "                        self.dx = abs(self.dx)\n",
    "                        self.dy = abs(self.dy)\n",
    "        else:\n",
    "            self.score = 0\n",
    "\n",
    "        if self.y < 0 or self.y > self.height_px:\n",
    "            self.dy = -self.dy\n",
    "\n",
    "    def dibujar_frame(self):\n",
    "        fig = plt.figure(figsize=(5, 4))\n",
    "        a1 = plt.gca()\n",
    "        circle = plt.Circle((self.x, self.y), self.radio, fc='slategray', ec=\"black\")\n",
    "        a1.set_ylim(-5, self.height_px+5)\n",
    "        a1.set_xlim(-5, self.width_px+5)\n",
    "\n",
    "        rectangle = plt.Rectangle((-5, self.player1), 5, self.player_alto, fc='gold', ec=\"none\")\n",
    "        a1.add_patch(circle);\n",
    "        a1.add_patch(rectangle)\n",
    "        #a1.set_yticklabels([]);a1.set_xticklabels([]);\n",
    "        plt.text(4, self.height_px, \"SCORE:\"+str(self.total_reward)+\"  LIFE:\"+str(self.lives), fontsize=12)\n",
    "        if self.lives <=0:\n",
    "            plt.text(10, self.height_px-14, \"GAME OVER\", fontsize=16)\n",
    "        elif self.total_reward >= 1000:\n",
    "            plt.text(10, self.height_px-14, \"YOU WIN!\", fontsize=16)\n",
    "        return fig\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def play(rounds=5000, max_life=3, discount_factor = 0.1, learning_rate = 0.1,\n",
    "         ratio_explotacion=0.9,learner=None, game=None, animate=False):\n",
    "\n",
    "    if game is None:\n",
    "        # si usamos movimiento_px = 5 creamos una tabla de politicas de 8x10\n",
    "        # si usamos movimiento_px = 3 la tabla sera de 14x17\n",
    "        game = PongEnvironment(max_life=max_life, movimiento_px = 3)\n",
    "        \n",
    "    if learner is None:\n",
    "        print(\"Begin new Train!\")\n",
    "        learner = PongAgent(game, discount_factor = discount_factor,learning_rate = learning_rate, ratio_explotacion= ratio_explotacion)\n",
    "\n",
    "    max_points= -9999\n",
    "    first_max_reached = 0\n",
    "    total_rw=0\n",
    "    steps=[]\n",
    "\n",
    "    for played_games in range(0, rounds):\n",
    "        state = game.reset()\n",
    "        reward, done = None, None\n",
    "        \n",
    "        itera=0\n",
    "        while (done != True) and (itera < 3000 and game.total_reward<=1000):\n",
    "            old_state = np.array(state)\n",
    "            next_action = learner.get_next_step(state, game)\n",
    "            state, reward, done = game.step(next_action, animate=animate)\n",
    "            if rounds > 1:\n",
    "                learner.update(game, old_state, next_action, reward, state, done)\n",
    "            itera+=1\n",
    "        \n",
    "        steps.append(itera)\n",
    "        \n",
    "        total_rw+=game.total_reward\n",
    "        if game.total_reward > max_points:\n",
    "            max_points=game.total_reward\n",
    "            first_max_reached = played_games\n",
    "        \n",
    "        if played_games %500==0 and played_games >1 and not animate:\n",
    "            print(\"-- Partidas[\", played_games, \"] Avg.Puntos[\", int(total_rw/played_games),\"]  AVG Steps[\", int(np.array(steps).mean()), \"] Max Score[\", max_points,\"]\")\n",
    "                \n",
    "    if played_games>1:\n",
    "        print('Partidas[',played_games,'] Avg.Puntos[',int(total_rw/played_games),'] Max score[', max_points,'] en partida[',first_max_reached,']')\n",
    "        \n",
    "    #learner.print_policy()\n",
    "    \n",
    "    return learner, game\n",
    "\n",
    "\n",
    "learner, game = play(rounds=5000, discount_factor = 0.2, learning_rate = 0.1, ratio_explotacion=0.85)\n",
    "\n",
    "learner2 = PongAgent(game, policy=learner.get_policy())\n",
    "learner2.ratio_explotacion = 1.0  # con esto quitamos las elecciones aleatorias al jugar\n",
    "player = play(rounds=1, learner=learner2, game=game, animate=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10592b8b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e8e6c69",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
